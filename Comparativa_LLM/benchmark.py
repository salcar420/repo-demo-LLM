import time
import ollama
import csv
import psutil  # <--- NUEVO: Para medir memoria RAM y CPU
import os

# --- 1. CONFIGURACI√ìN PROFESIONAL ---
modelos = ['llama3', 'mistral', 'gemma:7b']

# --- AHORA LOS PROMPTS TIENEN CATEGOR√çA ---
# Esto te permitir√° hacer gr√°ficos por "Habilidad" en Excel
prompts_data = [
    {
        "categoria": "Creatividad",
        "prompt": "Escribe un poema corto sobre el silencio en el espacio."
    },
    {
        "categoria": "Razonamiento",
        "prompt": "Tengo 5 camisas sec√°ndose al sol y tardan 2 horas. Si pongo 10 camisas, ¬øcu√°nto tardan? Explica tu l√≥gica."
    },
    {
        "categoria": "Coding",
        "prompt": "Escribe una funci√≥n simple en Python para detectar si una palabra es un pal√≠ndromo."
    },
    {
        "categoria": "Resumen",
        "prompt": "Resume el siguiente texto en una frase: 'La inteligencia artificial es una rama de la inform√°tica que busca simular la inteligencia humana en m√°quinas.'"
    }
]

archivo_csv = 'benchmark_pro.csv'

# Funci√≥n para obtener uso de RAM en MB
def obtener_uso_ram():
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024  # Convertir a MB

# --- 2. FUNCI√ìN PRINCIPAL ---
def correr_benchmark():
    print(f"üöÄ Iniciando Benchmark PROFESIONAL de {len(modelos)} modelos...")
    print(f"üß™ Se evaluar√°n {len(prompts_data)} categor√≠as por modelo.")
    print(f"üìÇ Guardando en: {archivo_csv}\n")

    with open(archivo_csv, mode='w', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        # --- NUEVAS COLUMNAS: Categor√≠a, RAM y CPU ---
        writer.writerow(['Modelo', 'Categoria', 'Prompt', 'Latencia_TTFT(s)', 'Total_Time(s)', 'Tokens_Seg(t/s)', 'RAM_Usada(MB)', 'Tokens_Total'])
        
        print(f"{'MODELO':<12} | {'CATEGORIA':<12} | {'VELOCIDAD':<10} | {'RAM (MB)':<10} | {'ESTADO'}")
        print("-" * 75)

        for modelo in modelos:
            for item in prompts_data:
                categoria = item['categoria']
                prompt = item['prompt']
                
                try:
                    # Medimos RAM antes de empezar
                    ram_inicio = psutil.virtual_memory().used / (1024 * 1024)
                    
                    start_time = time.time()
                    
                    # --- CONFIGURACI√ìN AVANZADA ---
                    # options={'temperature': 0} hace que el modelo sea m√°s l√≥gico y menos "loco"
                    response = ollama.chat(
                        model=modelo, 
                        messages=[{'role': 'user', 'content': prompt}], 
                        stream=True,
                        options={'temperature': 0.1} 
                    )
                    
                    first_token_time = None
                    token_count = 0
                    
                    for chunk in response:
                        if first_token_time is None:
                            first_token_time = time.time()
                        token_count += 1
                    
                    end_time = time.time()
                    
                    # Medimos RAM al final (aproximaci√≥n del pico de carga del sistema)
                    ram_fin = psutil.virtual_memory().used / (1024 * 1024)
                    ram_delta = ram_fin - ram_inicio # Cu√°nto subi√≥ la RAM
                    
                    # C√°lculos
                    ttft = first_token_time - start_time if first_token_time else 0
                    total_time = end_time - start_time
                    tps = token_count / total_time if total_time > 0 else 0
                    
                    # Guardamos datos enriquecidos
                    writer.writerow([
                        modelo, 
                        categoria, 
                        prompt, 
                        f"{ttft:.4f}", 
                        f"{total_time:.4f}", 
                        f"{tps:.2f}", 
                        f"{ram_delta:.2f}", # Nueva m√©trica
                        token_count
                    ])
                    
                    print(f"{modelo:<12} | {categoria:<12} | {tps:<10.2f} | {ram_delta:<10.2f} | ‚úÖ OK")

                except Exception as e:
                    print(f"{modelo:<12} | {categoria:<12} | ERROR      | 0.00       | ‚ùå {e}")

    print("\n" + "="*30)
    print("‚úÖ ¬°BENCHMARK PRO COMPLETADO!")

if __name__ == "__main__":
    correr_benchmark()